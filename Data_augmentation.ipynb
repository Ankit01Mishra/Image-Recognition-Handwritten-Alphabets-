{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "FhPQwnV2_8S6",
    "outputId": "bf2cdec4-97b3-4e2b-fd18-3ca209415d61"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "##loading the dependencies\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L1GxRQ2fP73-"
   },
   "source": [
    "#**Introduction TO Problem Domain**\n",
    "\n",
    "**In this section we are using the common stack of libraries for computer vision**\n",
    "\n",
    "1.   Pandas \n",
    "2.   Numpy\n",
    "3.   martplotlib.pyplot\n",
    "4.   Keras\n",
    "5.   tensorflow\n",
    "\n",
    "*in this section we are going to load the data in google colab notebook using kaggle API as our data is provided at kaggle.\n",
    "we will do some kind of EDA \n",
    "well this is not much required for the case og computer vision*\n",
    "\n",
    "**We are going to deal with image recognition task.**\n",
    "\n",
    "**Problem Statement:----**\n",
    "\n",
    "**We have been given to classify the Hand Written Alphabets.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nn32AA79P5oT"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.9</th>\n",
       "      <th>...</th>\n",
       "      <th>0.639</th>\n",
       "      <th>0.640</th>\n",
       "      <th>0.641</th>\n",
       "      <th>0.642</th>\n",
       "      <th>0.643</th>\n",
       "      <th>0.644</th>\n",
       "      <th>0.645</th>\n",
       "      <th>0.646</th>\n",
       "      <th>0.647</th>\n",
       "      <th>0.648</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  ...    0.639  0.640  0.641  \\\n",
       "0  0    0    0    0    0    0    0    0    0    0  ...        0      0      0   \n",
       "1  0    0    0    0    0    0    0    0    0    0  ...        0      0      0   \n",
       "2  0    0    0    0    0    0    0    0    0    0  ...        0      0      0   \n",
       "3  0    0    0    0    0    0    0    0    0    0  ...        0      0      0   \n",
       "4  0    0    0    0    0    0    0    0    0    0  ...        0      0      0   \n",
       "5  0    0    0    0    0    0    0    0    0    0  ...        0      0      0   \n",
       "6  0    0    0    0    0    0    0    0    0    0  ...        0      0      0   \n",
       "7  0    0    0    0    0    0    0    0    0    0  ...        0      0      0   \n",
       "\n",
       "   0.642  0.643  0.644  0.645  0.646  0.647  0.648  \n",
       "0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0      0  \n",
       "5      0      0      0      0      0      0      0  \n",
       "6      0      0      0      0      0      0      0  \n",
       "7      0      0      0      0      0      0      0  \n",
       "\n",
       "[8 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Loading the dataset\n",
    "df = pd.read_csv('A_Z Handwritten Data.csv')\n",
    "df.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "colab_type": "code",
    "id": "kgxlYZ-5Pstr",
    "outputId": "9194dbb4-ba5c-4572-8c50-10b5b1f961ed"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/seaborn/categorical.py:1428: FutureWarning: remove_na is deprecated and is a private function. Do not use.\n",
      "  stat_data = remove_na(group_data)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f4503b34128>"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7wAAAFzCAYAAAAdYgV/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f44a6a0d6d8>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Basic analysis\n",
    "\n",
    "# count plot\n",
    "plt.figure(figsize = (16,6))\n",
    "import seaborn as sns\n",
    "x = df['0'].sort_values(axis = 0)\n",
    "sns.countplot(x)\n",
    "\n",
    "'''\n",
    "this is highly imbalanced dataset\n",
    "we'll see how to deal with this in the data agumentation section.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "JJeNdfcARpIp",
    "outputId": "9e98e73c-dbca-4d47-cf4d-bfaf7b86c890"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 16, 17, 21, 22, 23, 24, 25] is the list containing alphabets having low no of counts\n",
      "19 is the total number of columns\n"
     ]
    }
   ],
   "source": [
    "##Lets filter out the classes having undersampled dataset\n",
    "x_count = pd.DataFrame(df['0'].value_counts()).astype(int)\n",
    "alpha_list = [i for i in range(26) if x_count['0'][i] < 14000]\n",
    "print(alpha_list,'is the list containing alphabets having low no of counts')\n",
    "print(len(alpha_list),'is the total number of columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "colab_type": "code",
    "id": "dhibJkmOSa_T",
    "outputId": "b107a73a-2fb0-4d1f-de8f-42338071e396"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.9</th>\n",
       "      <th>...</th>\n",
       "      <th>0.639</th>\n",
       "      <th>0.640</th>\n",
       "      <th>0.641</th>\n",
       "      <th>0.642</th>\n",
       "      <th>0.643</th>\n",
       "      <th>0.644</th>\n",
       "      <th>0.645</th>\n",
       "      <th>0.646</th>\n",
       "      <th>0.647</th>\n",
       "      <th>0.648</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>372450.000000</td>\n",
       "      <td>372450.0</td>\n",
       "      <td>372450.0</td>\n",
       "      <td>372450.0</td>\n",
       "      <td>372450.0</td>\n",
       "      <td>372450.0</td>\n",
       "      <td>372450.0</td>\n",
       "      <td>372450.0</td>\n",
       "      <td>372450.0</td>\n",
       "      <td>372450.0</td>\n",
       "      <td>...</td>\n",
       "      <td>372450.000000</td>\n",
       "      <td>372450.000000</td>\n",
       "      <td>372450.000000</td>\n",
       "      <td>372450.000000</td>\n",
       "      <td>372450.000000</td>\n",
       "      <td>372450.000000</td>\n",
       "      <td>372450.000000</td>\n",
       "      <td>372450.000000</td>\n",
       "      <td>372450.000000</td>\n",
       "      <td>372450.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13.523490</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001616</td>\n",
       "      <td>0.001592</td>\n",
       "      <td>0.001117</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>0.000618</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.740824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.490788</td>\n",
       "      <td>0.517297</td>\n",
       "      <td>0.421332</td>\n",
       "      <td>0.419180</td>\n",
       "      <td>0.385566</td>\n",
       "      <td>0.319820</td>\n",
       "      <td>0.208942</td>\n",
       "      <td>0.335227</td>\n",
       "      <td>0.134852</td>\n",
       "      <td>0.006554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>229.000000</td>\n",
       "      <td>228.000000</td>\n",
       "      <td>235.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0       0.1       0.2       0.3       0.4       0.5  \\\n",
       "count  372450.000000  372450.0  372450.0  372450.0  372450.0  372450.0   \n",
       "mean       13.523490       0.0       0.0       0.0       0.0       0.0   \n",
       "std         6.740824       0.0       0.0       0.0       0.0       0.0   \n",
       "min         0.000000       0.0       0.0       0.0       0.0       0.0   \n",
       "25%        10.000000       0.0       0.0       0.0       0.0       0.0   \n",
       "50%        14.000000       0.0       0.0       0.0       0.0       0.0   \n",
       "75%        18.000000       0.0       0.0       0.0       0.0       0.0   \n",
       "max        25.000000       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "            0.6       0.7       0.8       0.9      ...                0.639  \\\n",
       "count  372450.0  372450.0  372450.0  372450.0      ...        372450.000000   \n",
       "mean        0.0       0.0       0.0       0.0      ...             0.001616   \n",
       "std         0.0       0.0       0.0       0.0      ...             0.490788   \n",
       "min         0.0       0.0       0.0       0.0      ...             0.000000   \n",
       "25%         0.0       0.0       0.0       0.0      ...             0.000000   \n",
       "50%         0.0       0.0       0.0       0.0      ...             0.000000   \n",
       "75%         0.0       0.0       0.0       0.0      ...             0.000000   \n",
       "max         0.0       0.0       0.0       0.0      ...           252.000000   \n",
       "\n",
       "               0.640          0.641          0.642          0.643  \\\n",
       "count  372450.000000  372450.000000  372450.000000  372450.000000   \n",
       "mean        0.001592       0.001117       0.000929       0.000685   \n",
       "std         0.517297       0.421332       0.419180       0.385566   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max       226.000000     229.000000     228.000000     235.000000   \n",
       "\n",
       "               0.644          0.645          0.646          0.647  \\\n",
       "count  372450.000000  372450.000000  372450.000000  372450.000000   \n",
       "mean        0.000596       0.000618       0.000690       0.000239   \n",
       "std         0.319820       0.208942       0.335227       0.134852   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max       194.000000     103.000000     198.000000      82.000000   \n",
       "\n",
       "               0.648  \n",
       "count  372450.000000  \n",
       "mean        0.000011  \n",
       "std         0.006554  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         4.000000  \n",
       "\n",
       "[8 rows x 785 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## lets check the distribution of the dataset\n",
    "df.describe()\n",
    "\n",
    "'''\n",
    "Thus we see that there are some columns with mean 0 and they are useless in some sense so it requires use of PCA to project in lower subspace.\n",
    "It is assumed that the max pixel value is 255.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_52iieKNTUPm"
   },
   "source": [
    "# Image Formation out of csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "colab_type": "code",
    "id": "vVPu2FyQTbiJ",
    "outputId": "db5794eb-c046-4c70-a95a-f989140e7bee"
   },
   "outputs": [],
   "source": [
    "## its time to convert the dataframe in to images of size 28X28X1 as it is gray scaled\n",
    "##just using a subset for demonstration\n",
    "X = df.iloc[:1000,1:].values\n",
    "y = df.iloc[:1000,[0]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ci-dVGUQUJs-",
    "outputId": "2cbaf42c-9d04-4781-a4ad-fe4c5e8a9f4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "## resizing \n",
    "X = X.astype('float32')\n",
    "X = X/255.0\n",
    "\n",
    "X = X.reshape(-1,28,28,1)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "meQqDXqjUhts"
   },
   "outputs": [],
   "source": [
    "#deleting df,X,y\n",
    "del df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401
    },
    "colab_type": "code",
    "id": "_7w5kAWIU7xy",
    "outputId": "bc23e1cd-75ef-4c2c-813b-b682b22438d2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f964318b7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nThus we found that the labels are consistance enough\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##lets plotlone of the image\n",
    "plt.imshow(X[0][:,:,0])\n",
    "plt.show()\n",
    "\n",
    "##checking if the image is consistance with the label\n",
    "print(y[0])\n",
    "\n",
    "'''\n",
    "Thus we found that the labels are consistance enough\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "NHY1zo8uVLU2"
   },
   "outputs": [],
   "source": [
    "## as we have less data for some of the alphabets so lets create own dataset and lebels for that section using something called\n",
    "## data agumentation\n",
    "\n",
    "##required library is \n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CyW-XCiiWTKw"
   },
   "source": [
    "# Data Agumentation\n",
    "**Image agumentation is the process of taking images that are already in training data and manipulating them to create many altered versions of the same image.**\n",
    "**Advantages---->**\n",
    "**Provides more images to training and also exposes our classifier to wider variety of lighting and coloring situations and to make our classifier more robust.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "-XsPHNabWIEs"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    463\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m         \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileno\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_idat' object has no attribute 'fileno'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-90fe417fc6b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mimage_agumentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-90fe417fc6b5>\u001b[0m in \u001b[0;36mimage_agumentation\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;31m##calling the functions for our task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mimage_standardization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0mzca_whitening\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mrandom_rotations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-eca3c6973f85>\u001b[0m in \u001b[0;36mimage_standardization\u001b[0;34m(x_alpha, y_alpha)\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;31m#configuring the batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_alpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mx_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_label\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_alpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_alpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_to_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'images'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'std'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    980\u001b[0m         \u001b[0;31m# The transformation of images is not under thread lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m         \u001b[0;31m# so it can be done in parallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 982\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[0;34m(self, index_array)\u001b[0m\n\u001b[1;32m    962\u001b[0m                                                                   \u001b[0mhash\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m                                                                   format=self.save_format)\n\u001b[0;32m--> 964\u001b[0;31m                 \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_to_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    965\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   1891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1892\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1893\u001b[0;31m             \u001b[0msave_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1894\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1895\u001b[0m             \u001b[0;31m# do what we can to clean up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/PIL/PngImagePlugin.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, filename, chunk, check)\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m     ImageFile._save(im, _idat(fp, chunk),\n\u001b[0;32m--> 796\u001b[0;31m                     [(\"zip\", (0, 0)+im.size, 0, rawmode)])\n\u001b[0m\u001b[1;32m    797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m     \u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mb\"IEND\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    476\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m                     \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m                     \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def image_agumentation(X,y):\n",
    "  \n",
    "  '''\n",
    "  alpha_index is taken from alpha_list which contains the list of all those alphabets which are less in number.\n",
    "  '''\n",
    "  \n",
    "  ##getting the data for that alpha_index\n",
    "  \n",
    "  ##calling the functions for our task\n",
    "  image_standardization(X,y)\n",
    "  zca_whitening(X,y)\n",
    "  random_rotations(X,y)\n",
    "  random_shifts(X,y)\n",
    "  zoom_range(X,y)\n",
    "  \n",
    "  return True\n",
    "\n",
    "\n",
    "image_agumentation(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NKppbZoJce5j"
   },
   "source": [
    "# Background\n",
    "**ZCA whitening**\n",
    "\n",
    "**linear algebra operation that reduces the redundency in the matrix of pixel images,\n",
    "and less redundency in the image is intended to better highlight the structures and features in the image to the libear algorithm.\n",
    "Performed using PCA technique.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "1KZiBq_GZbAe"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#making a directory called images\n",
    "os.mkdir('images')\n",
    "\n",
    "\n",
    "## feature standardization\n",
    "def image_standardization(x_alpha,y_alpha):\n",
    "  datagen = ImageDataGenerator(featurewise_center = True,featurewise_std_normalization  = True)\n",
    "  datagen.fit(x_alpha)\n",
    "  #configuring the batch_size\n",
    "  batch_size = len(x_alpha)\n",
    "  for x_gen,y_label in datagen.flow(x_alpha,y_alpha,batch_size = batch_size,save_to_dir = 'images',save_prefix = 'std',save_format = 'png'):\n",
    "    continue\n",
    "    \n",
    "  return True\n",
    "\n",
    "## feature whitening\n",
    "def zca_whitening(x_alpha,y_alpha):\n",
    "  datagen = ImageDataGenerator(zca_whitening = True)\n",
    "  datagen.fit(x_alpha)\n",
    "  #configuring the batch_size\n",
    "  batch_size = len(x_alpha)\n",
    "  for x_gen,y_label in datagen.flow(x_alpha,y_alpha,batch_size = batch_size,save_to_dir = 'images',save_prefix = 'zca',save_format = 'png'):\n",
    "    continue\n",
    "  return True\n",
    "\n",
    "\n",
    "##random rotations\n",
    "def random_rotations(x_alpha,y_alpha):\n",
    "  datagen = ImageDataGenerator(rotation_range = 50)\n",
    "  datagen.fit(x_alpha)\n",
    "  #configuring the batch_size\n",
    "  batch_size = len(x_alpha)\n",
    "  for x_gen,y_label in datagen.flow(x_alpha,y_alpha,batch_size = batch_size,save_to_dir = 'images',save_prefix = 'rand_rot',save_format = 'png'):\n",
    "    continue\n",
    "  return True\n",
    "\n",
    "def random_shifts(x_alpha,y_alpha):\n",
    "  datagen = ImageDataGenerator(width_shift_range = 0.2,height_shift_range = 0.2)\n",
    "  datagen.fit(x_alpha)\n",
    "  #configuring the batch_size\n",
    "  batch_size = len(x_alpha)\n",
    "  for x_gen,y_label in datagen.flow(x_alpha,y_alpha,batch_size = batch_size,save_to_dir = 'images',save_prefix = 'rand-shift',save_format = 'png'):\n",
    "    continue\n",
    "  return True\n",
    "\n",
    "def zoom_range(x_alpha,y_alpha):\n",
    "  datagen = ImageDataGenerator(zoom_range = 0.2)\n",
    "  datagen.fit(x_alpha)\n",
    "  #configuring the batch_size\n",
    "  batch_size = len(x_alpha)\n",
    "  for x_gen,y_label in datagen.flow(x_alpha,y_alpha,batch_size = batch_size,save_to_dir = 'images',save_prefix = 'zoom',save_format = 'png'):\n",
    "    continue\n",
    "  return True\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "yVk-r6BVdJ4o"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Handwritten_digit_classification",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
